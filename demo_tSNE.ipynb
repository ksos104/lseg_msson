{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "# Modified by Bowen Cheng from: https://github.com/facebookresearch/detectron2/blob/master/demo/demo.py\n",
    "import argparse\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# fmt: off\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "# fmt: on\n",
    "\n",
    "import tempfile\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.detection_utils import read_image\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "from mask_former import add_mask_former_config\n",
    "from predictor import VisualizationDemo\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# constants\n",
    "WINDOW_NAME = \"MaskFormer demo\"\n",
    "\n",
    "\n",
    "def setup_cfg(args):\n",
    "    # load config from file and command-line arguments\n",
    "    cfg = get_cfg()\n",
    "    add_deeplab_config(cfg)\n",
    "    add_mask_former_config(cfg)\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.freeze()\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"Detectron2 demo for builtin configs\")\n",
    "    parser.add_argument(\n",
    "        \"--config-file\",\n",
    "        default=\"configs/ade20k-150/maskformer_R50_bs16_160k.yaml\",\n",
    "        metavar=\"FILE\",\n",
    "        help=\"path to config file\",\n",
    "    )\n",
    "    parser.add_argument(\"--webcam\", action=\"store_true\", help=\"Take inputs from webcam.\")\n",
    "    parser.add_argument(\"--video-input\", help=\"Path to video file.\")\n",
    "    parser.add_argument(\n",
    "        \"--input\",\n",
    "        nargs=\"+\",\n",
    "        help=\"A list of space separated input images; \"\n",
    "        \"or a single glob pattern such as 'directory/*.jpg'\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        help=\"A file or directory to save output visualizations. \"\n",
    "        \"If not given, will show output in an OpenCV window.\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--confidence-threshold\",\n",
    "        type=float,\n",
    "        default=0.5,\n",
    "        help=\"Minimum score for instance predictions to be shown\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--opts\",\n",
    "        help=\"Modify config options using the command-line 'KEY VALUE' pairs\",\n",
    "        default=[],\n",
    "        nargs=argparse.REMAINDER,\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "\n",
    "def test_opencv_video_format(codec, file_ext):\n",
    "    with tempfile.TemporaryDirectory(prefix=\"video_format_test\") as dir:\n",
    "        filename = os.path.join(dir, \"test_file\" + file_ext)\n",
    "        writer = cv2.VideoWriter(\n",
    "            filename=filename,\n",
    "            fourcc=cv2.VideoWriter_fourcc(*codec),\n",
    "            fps=float(30),\n",
    "            frameSize=(10, 10),\n",
    "            isColor=True,\n",
    "        )\n",
    "        [writer.write(np.zeros((10, 10, 3), np.uint8)) for _ in range(30)]\n",
    "        writer.release()\n",
    "        if os.path.isfile(filename):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "    # args = get_parser().parse_args()\n",
    "    \n",
    "    import easydict\n",
    "    \n",
    "    args = easydict.EasyDict({\n",
    "        \"config_file\": \"../configs/pascal_voc/zegformer_R101_bs32_10k_vit16_voc_gzss_eval.yaml\",\n",
    "        \"input\": [\"/mnt/server14_hard1/msson/datasets/zs3_datasets/VOCZERO/images/val/*.jpg\"],\n",
    "        \"opts\": [\"MODEL.WEIGHTS\",\"../trained/zegformer_R101_bs32_10k_vit16_voc.pth\"],\n",
    "        # \"opts\": [\"MODEL.WEIGHTS\",\"../output_clipsim_topk3_not_voc32/model_final.pth\",\"MODEL.PROMPT_ENSEMBLE_TYPE\",\"topk3\"],\n",
    "        \"output\": None\n",
    "    })\n",
    "    \n",
    "    setup_logger(name=\"fvcore\")\n",
    "    logger = setup_logger()\n",
    "    logger.info(\"Arguments: \" + str(args))\n",
    "\n",
    "    cfg = setup_cfg(args)\n",
    "\n",
    "    demo = VisualizationDemo(cfg)\n",
    "\n",
    "    if args.input:\n",
    "        if len(args.input) == 1:\n",
    "            args.input = glob.glob(os.path.expanduser(args.input[0]))\n",
    "            assert args.input, \"The input path(s) was not found\"\n",
    "        for path in tqdm.tqdm(args.input, disable=not args.output):\n",
    "            # use PIL, to be consistent with evaluation\n",
    "            img = read_image(path, format=\"BGR\")\n",
    "            start_time = time.time()\n",
    "            x_cls, image_features, text_features = demo.get_features(img)\n",
    "            x_cls = x_cls.squeeze()\n",
    "            \n",
    "            import torch\n",
    "            \n",
    "            print(\"image_path: \", path)\n",
    "            \n",
    "            ## Masks & Image & Text\n",
    "            # features = torch.cat((x_cls, image_features, text_features), dim=0)\n",
    "            # tsne_np = TSNE(n_components=2).fit_transform(features.cpu())\n",
    "            # tsne_df = pd.DataFrame(tsne_np, columns = ['component 0', 'component 1'])\n",
    "            \n",
    "            # tsne_df_x = tsne_df[:100]\n",
    "            # tsne_df_img = tsne_df[100:200]\n",
    "            # tsne_df_text = tsne_df[200:]\n",
    "            \n",
    "            # plt.scatter(tsne_df_x['component 0'], tsne_df_x['component 1'], color = 'yellow', label = 'mask')\n",
    "            # plt.scatter(tsne_df_img['component 0'], tsne_df_img['component 1'], color = 'blue', label = 'image')\n",
    "            # plt.scatter(tsne_df_text['component 0'], tsne_df_text['component 1'], color = 'purple', label = 'text')\n",
    "            \n",
    "            # plt.xlabel('component 0')\n",
    "            # plt.ylabel('component 1')\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "            \n",
    "            # ## Masks & Text\n",
    "            # features = torch.cat((x_cls, text_features), dim=0)\n",
    "            # tsne_np = TSNE(n_components=2).fit_transform(features.cpu())\n",
    "            # tsne_df = pd.DataFrame(tsne_np, columns = ['component 0', 'component 1'])\n",
    "            \n",
    "            # tsne_df_x = tsne_df[:100]\n",
    "            # tsne_df_text = tsne_df[100:]\n",
    "            \n",
    "            # plt.scatter(tsne_df_x['component 0'], tsne_df_x['component 1'], color = 'blue', label = 'mask')\n",
    "            # plt.scatter(tsne_df_text['component 0'], tsne_df_text['component 1'], color = 'purple', label = 'text')\n",
    "            \n",
    "            # plt.xlabel('component 0')\n",
    "            # plt.ylabel('component 1')\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "            \n",
    "            ## Image & Text\n",
    "            features = torch.cat((image_features, text_features), dim=0)\n",
    "            tsne_np = TSNE(n_components=2).fit_transform(features.cpu())\n",
    "            tsne_df = pd.DataFrame(tsne_np, columns = ['component 0', 'component 1'])\n",
    "            \n",
    "            tsne_df_img = tsne_df[:100]\n",
    "            tsne_df_text = tsne_df[100:]\n",
    "            \n",
    "            plt.scatter(tsne_df_img['component 0'], tsne_df_img['component 1'], color = 'blue', label = 'image')\n",
    "            plt.scatter(tsne_df_text['component 0'], tsne_df_text['component 1'], color = 'purple', label = 'text')\n",
    "            \n",
    "            plt.xlabel('component 0')\n",
    "            plt.ylabel('component 1')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "            ## Masks only\n",
    "            # tsne_np = TSNE(n_components=2).fit_transform(x_cls.cpu())\n",
    "            # tsne_df = pd.DataFrame(tsne_np, columns = ['component 0', 'component 1'])\n",
    "            \n",
    "            # plt.scatter(tsne_df['component 0'], tsne_df['component 1'], color = 'blue', label = 'mask')\n",
    "            \n",
    "            # plt.xlabel('component 0')\n",
    "            # plt.ylabel('component 1')\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "            \n",
    "            # ## Image only\n",
    "            # tsne_np = TSNE(n_components=2).fit_transform(image_features.cpu())\n",
    "            # tsne_df = pd.DataFrame(tsne_np, columns = ['component 0', 'component 1'])\n",
    "            \n",
    "            # plt.scatter(tsne_df['component 0'], tsne_df['component 1'], color = 'yellow', label = 'image')\n",
    "            \n",
    "            # plt.xlabel('component 0')\n",
    "            # plt.ylabel('component 1')\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "            \n",
    "            # ## Text only\n",
    "            # tsne_np = TSNE(n_components=2).fit_transform(text_features.cpu())\n",
    "            # tsne_df = pd.DataFrame(tsne_np, columns = ['component 0', 'component 1'])\n",
    "            \n",
    "            # plt.scatter(tsne_df['component 0'], tsne_df['component 1'], color = 'purple', label = 'text')\n",
    "            \n",
    "            # plt.xlabel('component 0')\n",
    "            # plt.ylabel('component 1')\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msson_zs3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf13b08ca8e6013fc740bb0314b5f4c54108d8d855c89188c383e80d2a061427"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
